
#### Multithreaded Server Architecture

![[Pasted image 20241015162002.png]]

#### Benefits

▪ Responsiveness – may allow continued execution if part of 
process is blocked, especially important for user interfaces
▪ Resource Sharing – threads share resources of process, easier 
than shared memory or message passing
▪ Economy – cheaper than process creation, thread switching 
lower overhead than context switching
▪ Scalability – process can take advantage of multicore 
architectures

▪ Parallelism implies a system can perform more than one task 
simultaneously
▪ Concurrency supports more than one task making progress
	• Single processor / core, scheduler providing concurrency

![[Pasted image 20241015162240.png]]

▪ Types of parallelism 
	• Data parallelism – distributes subsets of the same data 
	  across multiple cores, same operation on each
	• Task parallelism – distributing threads across cores, each 
	   thread performing unique operation

#### Amdahl's Law

![[Pasted image 20241015163141.png]]

- **S** represents the portion of the program that is serial and cannot be parallelized.
- **1 - S** is the parallelizable portion.
- **N** is the number of processing cores or units.

▪ User threads - management done by user-level threads library
	• POSIX Pthreads
	• Windows threads
	• Java threads
	
▪ Kernel threads - Supported by the Kernel
	• Windows 
	• Linux
	• Mac OS X
	• iOS
	• Android

#### Multithreading Models

1. Many-to-One Multithreading Model

In the **Many-to-One** multithreading model, multiple user-level threads are mapped to a single kernel thread.

**Key Characteristics:**

- **Blocking:** If one user thread makes a blocking call, all other threads are blocked since they share the same kernel thread.
- **No True Parallelism:** Even on multicore systems, true parallelism isn't possible because only one thread can be in the kernel at any time.
- **Limited Use:** This model is rarely used today due to its limitations in performance and efficiency.

**Examples:**

- **Solaris Green Threads** and **GNU Portable Threads** implement this model.

![[Pasted image 20241015173913.png]]

2. One-to-One Multithreading Model

In the **One-to-One** model, each user-level thread is mapped to a separate kernel thread.

**Key Characteristics:**

- **Concurrency:** Offers greater concurrency than the many-to-one model, as multiple threads can run in parallel on multicore systems.
- **Thread Creation:** Each time a user-level thread is created, a corresponding kernel thread is created, allowing the OS to manage scheduling and execution.
- **Overhead:** High overhead due to managing many kernel threads, leading some systems to limit the number of threads per process.

**Examples:**

- **Windows** and **Linux** implement the one-to-one model.

![[Pasted image 20241015174046.png]]

3. Many-to-Many Multithreading Model

In the **Many-to-Many** model, multiple user-level threads are mapped to an equal or smaller number of kernel threads.

**Key Characteristics:**

- **Flexibility:** The operating system can create a sufficient number of kernel threads to support user threads, allowing better utilization of system resources.
- **Concurrency:** It provides good concurrency by allowing multiple threads to run in parallel on multicore systems, without the limitations of the many-to-one model.
- **Efficiency:** Balances the flexibility of user-level threads with the system’s ability to manage kernel threads, reducing overhead.

**Example:**

- **Windows** (with the ThreadFiber package) supports this model, though it's not commonly used in other systems.

![[Pasted image 20241015174328.png]]


4. Two-Level Multithreading Model

The **Two-Level** model is a variant of the many-to-many model, with added flexibility.

![[Pasted image 20241015174826.png]]


#### Thread Libraries

A **thread library** provides programmers with an API to create, manage, and control threads in their applications.

**Two Primary Implementation Methods:**
1. **User-Space Library:**
    - The entire thread management is done in user space without kernel intervention.
    - Fast and efficient as no kernel mode switching is required.
    - Drawback: If one thread blocks, all threads in the process can be blocked, as the kernel is unaware of individual threads.
2. **Kernel-Level Library:**
    - Thread management is done by the operating system through kernel support.
    - Threads are recognized by the OS, allowing better scheduling and resource allocation.

#### Pthreads
- **Description:** A POSIX-compliant thread library used for creating and managing threads in Unix-like operating systems, including Linux and macOS. Pthreads can be implemented as either user-level or kernel-level threads, depending on the system.
- **Key Points:**
  - POSIX standard (IEEE 1003.1c) for thread creation and synchronization.
  - It's a specification, meaning the actual implementation can vary between systems.

**Example:**
```c
pthread_t tid; // Thread identifier
pthread_attr_t attr; // Thread attributes

pthread_attr_init(&attr); // Initialize attributes
pthread_create(&tid, &attr, runner, argv[1]); // Create thread
pthread_join(tid, NULL); // Wait for thread to finish
```

**Creating and Joining 10 Threads:**
```c
#define NUM_THREADS 10
pthread_t workers[NUM_THREADS];
for (int i = 0; i < NUM_THREADS; i++) {
    pthread_join(workers[i], NULL);
}
```

#### Windows Multithreaded C Program
- **Description:** In Windows, threads are created using the `CreateThread()` function. The system manages threads at the kernel level.
- **Key Points:**
  - Uses `CreateThread()` to spawn a new thread.
  - Waits for thread completion using `WaitForSingleObject()`.

**Example:**
```c
HANDLE ThreadHandle;
DWORD ThreadId;
ThreadHandle = CreateThread(NULL, 0, Summation, &Param, 0, &ThreadId);
WaitForSingleObject(ThreadHandle, INFINITE);
CloseHandle(ThreadHandle);
```

#### Java Threads
- **Description:** Java threads are managed by the JVM and typically rely on the underlying OS thread model. Java supports thread creation by either extending the `Thread` class or implementing the `Runnable` interface.
- **Key Points:**
  - Implementing `Runnable` is preferred over extending `Thread`.
  - Java provides a higher-level API for thread management.

**Example using `Runnable`:**
```java
class Task implements Runnable {
    public void run() {
        System.out.println("I am a thread.");
    }
}

Thread worker = new Thread(new Task());
worker.start();
```

**Waiting for Thread to Complete:**
```java
try {
    worker.join();
} catch (InterruptedException ie) { }
```

#### Java Executor Framework
- **Description:** Instead of managing threads manually, Java's Executor Framework provides a higher-level abstraction for managing threads through the `Executor` interface.
- **Key Points:**
  - `ExecutorService` allows managing thread pools and task execution.
  - More efficient for handling multiple concurrent tasks.

**Example using `ExecutorService`:**
```java
ExecutorService pool = Executors.newSingleThreadExecutor();
Future<Integer> result = pool.submit(new Summation(upper));

try {
    System.out.println("sum=" + result.get());
} catch (InterruptedException | ExecutionException ie) { }
```

### Implicit Threading

**Implicit threading** automates the creation and management of threads, reducing the burden on programmers. As the number of threads increases, explicit management becomes complex, making implicit threading a popular solution. 

**Key Points:**
- Thread creation and management are handled by **compilers** and **runtime libraries** instead of being explicitly written by programmers.
- This simplifies program development and improves correctness.

**Five Key Methods:**
1. **Thread Pools:** Pre-created threads await tasks, improving performance by reusing threads.
2. **Fork-Join:** A parallel programming model where tasks are recursively divided into subtasks.
3. **OpenMP:** A set of compiler directives for parallel programming, widely used in C, C++, and Fortran.
4. **Grand Central Dispatch (GCD):** A technology by Apple for managing concurrent code execution on multicore hardware.
5. **Intel Threading Building Blocks (TBB):** A C++ template library for parallel programming.

---
### Thread Pools

**Thread pools** maintain a pool of pre-created threads that await tasks, improving performance by reusing threads rather than creating new ones for each task.

**Advantages:**
- **Faster Response:** Reusing existing threads avoids the overhead of creating new ones.
- **Bounded Resources:** Limits the number of threads running simultaneously, improving resource management.
- **Task Flexibility:** Decouples the task creation from task execution, allowing for scheduling and other strategies.

Java Thread Pools

In Java, the **Executors** class provides factory methods to create different types of thread pools.

---
### Fork-Join Parallelism

**Fork-Join** is a parallel programming model where a task is divided into smaller subtasks, which are executed concurrently. Once the subtasks are completed, their results are combined to solve the original problem.

**General Algorithm:**

1. **Task(problem)**: Start with the original problem.
2. **Check size of the problem**:
    - If the problem is small enough, solve it directly (base case).
3. **Divide and Conquer**:
    - If the problem is large, split it into smaller subsets.
    - **Fork** new tasks for each subset (i.e., create concurrent threads to handle each subset).
4. **Join**:
    - Wait for the subtasks to finish and retrieve their results.
5. **Combine Results**:
    - Merge the results from the subtasks to produce the final solution.

---
### Threading Issues

Threading in operating systems presents several challenges, especially with system calls, signal handling, and thread management. Below is an overview of common threading issues:

---

#### **Semantics of fork() and exec()**
- **fork():** When a process with multiple threads calls `fork()`, there are two possible behaviors:
  - **Duplicate all threads** in the process.
  - **Duplicate only the calling thread** (common in modern UNIX systems).
  - Some UNIX systems provide two versions of `fork()`: one that duplicates all threads and another that duplicates only the calling thread.
  
- **exec():** When `exec()` is called, it replaces the entire process, including all threads, as usual. The new program replaces the current process image.

---

#### **Signal Handling**
Signals notify a process that a specific event has occurred, and a signal handler processes these signals.

- **Steps in Signal Handling**:
  1. Signal is generated by an event.
  2. Signal is delivered to the process.
  3. The signal is handled by:
     - **Default signal handler** (provided by the OS kernel).
     - **User-defined signal handler** (optional and overrides the default handler).

- **For Single-Threaded Processes**:
  - The signal is delivered to the entire process and handled by the default or user-defined handler.

---

#### **Signal Handling in Multi-Threaded Programs**
In a multi-threaded process, handling signals becomes more complex:

- **Delivery Options**:
  1. Deliver the signal to the **specific thread** that caused the signal (e.g., divide-by-zero error).
  2. Deliver the signal to **all threads** in the process.
  3. Deliver the signal to a **set of specific threads**.
  4. **Assign a dedicated thread** to handle all signals in the process.

---
#### **Thread Cancellation**
Thread cancellation refers to terminating a thread before it has completed execution. Two types exist:

1. **Asynchronous Cancellation**:
   - Terminates the target thread immediately, which can lead to inconsistent states or resource leaks.
   
2. **Deferred Cancellation**:
   - The target thread checks for cancellation at safe points (e.g., periodically or during specific operations).

---

#### **Thread-Local Storage (TLS)**
- **Thread-local storage** provides a way for each thread to have its own copy of data, ensuring that threads do not interfere with each other when accessing shared variables.

---

#### **Scheduler Activations**
- **Scheduler activations** provide an interface between the user-level threading library and the kernel, allowing user threads to run efficiently on a multi-core system. The kernel notifies the threading library when certain events (like blocking or unblocking of threads) occur, helping improve thread management.


### Operating System Examples: Windows Threads and Linux Threads

---

#### **Windows Threads**
- **Windows API**: The primary API for creating and managing threads in Windows.
- Implements a **one-to-one mapping** of user threads to kernel threads, meaning each user thread is associated with a kernel thread.
  
**Thread Components:**
- **Thread ID**: Unique identifier for the thread.
- **Register Set**: Represents the state of the processor when the thread is running.
- **Separate Stacks**: 
  - User mode stack (when the thread runs in user space).
  - Kernel mode stack (when the thread runs in kernel space).
- **Private Data Storage**: Used by runtime libraries and dynamic link libraries (DLLs).

**Thread Context**:
- The **context of a thread** includes its register set, stacks, and private storage. This context is essential for managing thread execution.

---

#### **Linux Threads**
- Linux refers to threads as **tasks**.
- Thread creation in Linux is handled via the `clone()` system call.

**Thread Creation (`clone()` System Call)**:
- **clone()** creates a child task (or thread) that can share resources with the parent process, such as memory space, file descriptors, or signal handlers.

**Key Flags for `clone()`**:
- **CLONE_FS**: Shares file system information (e.g., current working directory).
- **CLONE_VM**: Shares the same memory space (virtual memory).
- **CLONE_SIGHAND**: Shares signal handlers between parent and child threads.
- **CLONE_FILES**: Shares the set of open files between threads.

In Linux, **threads and processes** are treated similarly, with both being referred to as "tasks." They are managed with similar system calls, though threads typically share more resources like memory and file descriptors.